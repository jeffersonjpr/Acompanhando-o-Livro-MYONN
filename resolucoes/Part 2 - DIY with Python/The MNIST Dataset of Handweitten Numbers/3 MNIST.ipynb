{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import scipy.special #sigmoid function expit()\n",
    "import matplotlib.pyplot #plotting arrays\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição da classe Rede Neural\n",
    "class NeuralNet:\n",
    "    \n",
    "    #inicializar a rede\n",
    "    def __init__(self, inputN, hiddenN, outputN, learningR):\n",
    "        \n",
    "        #Configurar o numero de nós em cada camada\n",
    "        self.inodes = inputN\n",
    "        self.hnodes = hiddenN\n",
    "        self.onodes = outputN\n",
    "        \n",
    "        #taxa de aprendizado\n",
    "        self.lr = learningR\n",
    "        \n",
    "        #WEIGHTS\n",
    "        #link weigth wih (weights input --> hidden) and who (weights hidden --> output)\n",
    "        #self.wih = (numpy.random.rand(self.hnodes, self.inodes) - 0.5)\n",
    "        #self.who = (numpy.random.rand(self.onodes, self.hnodes) - 0.5)\n",
    "        \n",
    "        #Better weights\n",
    "        #Random weights from a normal probability distribution centred on zero\n",
    "        #standard deviation = 1/srqt(incoming links)\n",
    "        \n",
    "        #numpy.random.normal(mean, spread, shape)\n",
    "        self.wih = numpy.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = numpy.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes))\n",
    "        \n",
    "        #ACTIVATION FUNCTION\n",
    "        self.activation_function = lambda x : scipy.special.expit(x)\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    #treinar a rede\n",
    "    def train(self, inputs_list, targets_list):\n",
    "        #convertere para array2d numpy\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #PROPAGATION\n",
    "        #signals hiddenl\n",
    "        hi = numpy.dot(self.wih, inputs) #hidden inputs\n",
    "        ho = self.activation_function(hi) #hidden outputs\n",
    "        \n",
    "        #signals outputL\n",
    "        oi = numpy.dot(self.who, ho) #final inputs\n",
    "        oo = self.activation_function(oi) #final outputs\n",
    "        \n",
    "        #BACKpropagation\n",
    "        #ERRORS\n",
    "        output_errors = targets - oo #error = (target - actual)\n",
    "        hidden_errors = numpy.dot(self.who.T, output_errors) #ErrorsH = who.T dot errorsOut\n",
    "        \n",
    "        #UPDATING WEIGHTS\n",
    "        self.who += self.lr * numpy.dot((output_errors * oo * (1.0 - oo)), numpy.transpose(ho))\n",
    "        self.wih += self.lr * numpy.dot((hidden_errors * ho * (1.0 - ho)), numpy.transpose(inputs))\n",
    "        pass\n",
    "    \n",
    "    #resposta depois de treinada\n",
    "    def query(self, inputs_list):\n",
    "        \n",
    "        #Convertendo inputs para Array2d\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        #INPUT --> HIDDEN\n",
    "        #Hidden input calculation\n",
    "        hidden_inputs = numpy.dot(self.wih, inputs)\n",
    "        \n",
    "        #Hidden outputs (activation function)\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        #HIDDEN --> OUTPUT\n",
    "        #signals into the final layer (output layer)\n",
    "        output_inputs = numpy.dot(self.who, hidden_outputs)\n",
    "        #signals out the final layer (output layer)\n",
    "        output_outputs = self.activation_function(output_inputs)\n",
    "        \n",
    "        return output_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST NUMBERS Creating instance of the NN\n",
    "#INPUTS (Every pixel 28x28), hidden, output (10 possible numbers)\n",
    "inputl = 784\n",
    "hiddenl = 100\n",
    "outl = 10\n",
    "\n",
    "learningrate = 0.3\n",
    "\n",
    "nn = NeuralNet(inputl, hiddenl, outl, learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOADING THE DATA\n",
    "training_data_arq = open(\"mnist/mnist_train_100.csv\", \"r\")\n",
    "training_data_lista = training_data_arq.readlines()\n",
    "training_data_arq.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARING THE DATA and TRAINING THE NN\n",
    "for record in training_data_lista:\n",
    "    all_values = record.split(',') #separando a string atual pelas virgulas\n",
    "    inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01 #scaling the inputs\n",
    "    target = numpy.zeros(outl) + 0.01 #criando o target 0.01-0.99\n",
    "    target[int(all_values[0])] = 0.99 #target label\n",
    "    \n",
    "    nn.train(inputs, target)\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
